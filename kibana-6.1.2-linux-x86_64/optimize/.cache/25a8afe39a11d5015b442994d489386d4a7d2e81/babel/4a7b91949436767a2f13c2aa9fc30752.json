{"remainingRequest":"/home/vagrant/projects/kibana/build/kibana/node_modules/babel-loader/lib/index.js??ref--6-1!/home/vagrant/projects/kibana/build/kibana/src/ui/public/agg_response/hierarchical/_create_raw_data.js","dependencies":[{"path":"/home/vagrant/projects/kibana/build/kibana/src/ui/public/agg_response/hierarchical/_create_raw_data.js","mtime":1515552033000},{"path":"/home/vagrant/projects/kibana/build/kibana/node_modules/cache-loader/dist/cjs.js","mtime":1493198456000},{"path":"/home/vagrant/projects/kibana/build/kibana/node_modules/babel-loader/lib/index.js","mtime":1503096278000}],"contextDependencies":[],"result":["'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.createRawData = createRawData;\n\nvar _lodash = require('lodash');\n\nvar _lodash2 = _interopRequireDefault(_lodash);\n\nvar _extract_buckets = require('ui/agg_response/hierarchical/_extract_buckets');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction createRawData(vis, resp) {\n\n  // Create the initial results structure\n  var results = { rows: [] };\n\n  // Create a reference to the buckets and metrics\n  var metrics = vis.getAggConfig().bySchemaGroup.metrics;\n  var buckets = vis.getAggConfig().bySchemaGroup.buckets;\n  var aggs = [];\n\n  if (buckets) {\n    _lodash2.default.each(buckets, function (bucket) {\n      aggs.push(bucket);\n      aggs.push(metrics);\n    });\n  } else {\n    aggs.push(metrics);\n  }\n\n  // Create the columns\n  results.columns = (0, _lodash2.default)(aggs).flattenDeep().map(function (agg) {\n    return {\n      categoryName: agg.schema.name,\n      id: agg.id,\n      aggConfig: agg,\n      aggType: agg.type,\n      field: agg.params.field,\n      label: agg.makeLabel()\n    };\n  }).value();\n\n  // if there are no buckets then we need to just set the value and return\n  if (!buckets) {\n    var value = resp.aggregations && resp.aggregations[metrics[0].id] && resp.aggregations[metrics[0].id].value || resp.hits.total;\n    results.rows.push([value]);\n    return results;\n  }\n\n  /**\n   * Walk the buckets and create records for each leaf\n   * @param {aggConfig} agg The aggConfig for the current level\n   * @param {object} data The aggergation object\n   * @param {array} [record] The record that will eventually get pushed to the rows\n   * @returns {void}\n   */\n  function walkBuckets(agg, data, record) {\n    if (!data) return;\n    if (!Array.isArray(record)) {\n      record = [];\n    }\n\n    // iterate through all the buckets\n    _lodash2.default.each((0, _extract_buckets.extractBuckets)(data[agg.id], agg), function (bucket) {\n\n      var _record = _lodash2.default.flattenDeep([record, bucket.key]);\n      _lodash2.default.each(metrics, function (metric) {\n        var value = bucket.doc_count;\n        if (bucket[metric.id] && !_lodash2.default.isUndefined(bucket[metric.id].value)) {\n          value = bucket[metric.id].value;\n        }\n        _record.push(value);\n      });\n\n      // If there is another agg to call we need to check to see if it has\n      // buckets. If it does then we need to keep on walking the tree.\n      // This is where the recursion happens.\n      if (agg._next) {\n        var nextBucket = bucket[agg._next.id];\n        if (nextBucket && nextBucket.buckets) {\n          walkBuckets(agg._next, bucket, _record);\n        }\n      }\n      // if there are no more aggs to walk then  push the record to the rows.\n      else {\n          results.rows.push(_record);\n        }\n    });\n  }\n\n  // Start walking the buckets at the beginning of the aggregations object.\n  walkBuckets(buckets[0], resp.aggregations);\n\n  return results;\n}",null]}