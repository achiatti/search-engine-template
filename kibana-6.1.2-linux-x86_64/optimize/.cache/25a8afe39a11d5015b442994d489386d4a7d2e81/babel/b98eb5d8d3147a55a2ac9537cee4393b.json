{"remainingRequest":"/home/vagrant/projects/kibana/build/kibana/node_modules/babel-loader/lib/index.js??ref--6-1!/home/vagrant/projects/kibana/build/kibana/src/ui/public/agg_response/tabify/tabify.js","dependencies":[{"path":"/home/vagrant/projects/kibana/build/kibana/src/ui/public/agg_response/tabify/tabify.js","mtime":1515552033000},{"path":"/home/vagrant/projects/kibana/build/kibana/node_modules/cache-loader/dist/cjs.js","mtime":1493198456000},{"path":"/home/vagrant/projects/kibana/build/kibana/node_modules/babel-loader/lib/index.js","mtime":1503096278000}],"contextDependencies":[],"result":["'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.AggResponseTabifyProvider = AggResponseTabifyProvider;\n\nvar _lodash = require('lodash');\n\nvar _lodash2 = _interopRequireDefault(_lodash);\n\nvar _response_writer = require('ui/agg_response/tabify/_response_writer');\n\nvar _buckets = require('ui/agg_response/tabify/_buckets');\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction AggResponseTabifyProvider(Private, Notifier) {\n  var TabbedAggResponseWriter = Private(_response_writer.TabbedAggResponseWriterProvider);\n  var Buckets = Private(_buckets.AggResponseBucketsProvider);\n  var notify = new Notifier({ location: 'agg_response/tabify' });\n\n  function tabifyAggResponse(vis, esResponse, respOpts) {\n    var write = new TabbedAggResponseWriter(vis, respOpts);\n\n    var topLevelBucket = _lodash2.default.assign({}, esResponse.aggregations, {\n      doc_count: esResponse.hits.total\n    });\n\n    collectBucket(write, topLevelBucket, '', 1);\n\n    return write.response();\n  }\n\n  /**\n   * read an aggregation from a bucket, which is *might* be found at key (if\n   * the response came in object form), and will recurse down the aggregation\n   * tree and will pass the read values to the ResponseWriter.\n   *\n   * @param {object} bucket - a bucket from the aggResponse\n   * @param {undefined|string} key - the key where the bucket was found\n   * @returns {undefined}\n   */\n  function collectBucket(write, bucket, key, aggScale) {\n    var agg = write.aggStack.shift();\n    var aggInfo = agg.write();\n    aggScale *= aggInfo.metricScale || 1;\n\n    switch (agg.schema.group) {\n      case 'buckets':\n        var buckets = new Buckets(bucket[agg.id], agg.params);\n        if (buckets.length) {\n          var splitting = write.canSplit && agg.schema.name === 'split';\n          if (splitting) {\n            write.split(agg, buckets, function forEachBucket(subBucket, key) {\n              collectBucket(write, subBucket, agg.getKey(subBucket, key), aggScale);\n            });\n          } else {\n            buckets.forEach(function (subBucket, key) {\n              write.cell(agg, agg.getKey(subBucket, key), function () {\n                collectBucket(write, subBucket, agg.getKey(subBucket, key), aggScale);\n              });\n            });\n          }\n        } else if (write.partialRows && write.metricsForAllBuckets && write.minimalColumns) {\n          // we don't have any buckets, but we do have metrics at this\n          // level, then pass all the empty buckets and jump back in for\n          // the metrics.\n          write.aggStack.unshift(agg);\n          passEmptyBuckets(write, bucket, key, aggScale);\n          write.aggStack.shift();\n        } else {\n          // we don't have any buckets, and we don't have isHierarchical\n          // data, so no metrics, just try to write the row\n          write.row();\n        }\n        break;\n      case 'metrics':\n        var value = agg.getValue(bucket);\n        // since the aggregation could be a non integer (such as a max date)\n        // only do the scaling calculation if it is needed.\n        if (aggScale !== 1) {\n          value *= aggScale;\n        }\n        write.cell(agg, value, function () {\n          if (!write.aggStack.length) {\n            // row complete\n            write.row();\n          } else {\n            // process the next agg at this same level\n            collectBucket(write, bucket, key, aggScale);\n          }\n        });\n        break;\n    }\n\n    write.aggStack.unshift(agg);\n  }\n\n  // write empty values for each bucket agg, then write\n  // the metrics from the initial bucket using collectBucket()\n  function passEmptyBuckets(write, bucket, key, aggScale) {\n    var agg = write.aggStack.shift();\n\n    switch (agg.schema.group) {\n      case 'metrics':\n        // pass control back to collectBucket()\n        write.aggStack.unshift(agg);\n        collectBucket(write, bucket, key, aggScale);\n        return;\n\n      case 'buckets':\n        write.cell(agg, '', function () {\n          passEmptyBuckets(write, bucket, key, aggScale);\n        });\n    }\n\n    write.aggStack.unshift(agg);\n  }\n\n  return notify.timed('tabify agg response', tabifyAggResponse);\n}",null]}